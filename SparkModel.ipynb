{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dota match prediction based on the lineup\n",
    "The idea is to create a model able to predict the outcome of a dota match based only on the lineup of both teams.\n",
    "It is clear that the presition can never be very high: there are too many variables at play, expecially assuming the games are mostly balanced in terms of picks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports\n",
    "Let's start by importing all the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import StructType, StructField, DataFrame\n",
    "from pyspark.sql.types import ArrayType, IntegerType, LongType, BooleanType\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler, VectorSizeHint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the Spark Session\n",
    "Creates a Spark sessio for the app named _\"dotingestion\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://2af93ba81d4a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dotingestion</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f144af7ca90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName(\"dotingestion\").getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pre-Processing ðŸ”§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define a schema\n",
    "This is the schema that contains all the data we need:\n",
    "```yaml\n",
    "dire_lineup: [2, 14, 61, 96, 112]    # list of the hero_id the dire team picked\n",
    "radiant_lineup: [4, 12, 42, 45, 65]  # list of the hero_id the radiant team picked\n",
    "radiant_win: true                    # whether the radiant team won\n",
    "match_id: 10                         # sequential id of the match, to make sure each match is accounted for once\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(dire_lineup,ArrayType(IntegerType,false),false),StructField(radiant_lineup,ArrayType(IntegerType,false),false),StructField(radiant_win,BooleanType,false),StructField(match_id,LongType,false)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([StructField(\"dire_lineup\", ArrayType(IntegerType(), False), False),\n",
    "                    StructField(\"radiant_lineup\", ArrayType(IntegerType(), False), False),\n",
    "                    StructField(\"radiant_win\", BooleanType(), False),\n",
    "                    StructField(\"match_id\", LongType(), False)])\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Read the data\n",
    "Reads the matches data already collected from the _\"./data.json\"_ file.  \n",
    "Drops immedialy any null or repeated row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dire_lineup: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- radiant_lineup: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- radiant_win: boolean (nullable = true)\n",
      " |-- match_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"data.json\"\n",
    "df = sc.read.json(path, schema=schema).na.drop(\"all\").distinct()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73922"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+----------+\n",
      "|         dire_lineup|      radiant_lineup|radiant_win|  match_id|\n",
      "+--------------------+--------------------+-----------+----------+\n",
      "| [75, 88, 7, 44, 25]|[86, 41, 34, 43, ...|      false|5026549394|\n",
      "|[96, 94, 25, 103,...|[71, 67, 23, 84, 11]|      false|5026549581|\n",
      "| [2, 34, 68, 32, 76]| [53, 26, 90, 8, 75]|      false|5026549637|\n",
      "|[100, 28, 26, 12,...| [2, 52, 86, 94, 30]|      false|5026549793|\n",
      "|[129, 93, 75, 5, 35]| [73, 16, 44, 50, 2]|      false|5026549835|\n",
      "+--------------------+--------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Process data 1\n",
    "The hero_id values go from 1 to 135, but not all indeces are used.  \n",
    "For this reason, first we compact them in a dictionary based on the data in the _hero.json_ file, to map each possible value to an index going from **0** to **n**, where n is the number of possible hero_id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 11: 9,\n",
       " 10: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18,\n",
       " 20: 19,\n",
       " 21: 20,\n",
       " 22: 21,\n",
       " 23: 22,\n",
       " 25: 23,\n",
       " 31: 24,\n",
       " 26: 25,\n",
       " 27: 26,\n",
       " 28: 27,\n",
       " 29: 28,\n",
       " 30: 29,\n",
       " 32: 30,\n",
       " 33: 31,\n",
       " 34: 32,\n",
       " 35: 33,\n",
       " 36: 34,\n",
       " 37: 35,\n",
       " 38: 36,\n",
       " 39: 37,\n",
       " 40: 38,\n",
       " 41: 39,\n",
       " 42: 40,\n",
       " 43: 41,\n",
       " 44: 42,\n",
       " 45: 43,\n",
       " 46: 44,\n",
       " 47: 45,\n",
       " 48: 46,\n",
       " 49: 47,\n",
       " 50: 48,\n",
       " 51: 49,\n",
       " 52: 50,\n",
       " 53: 51,\n",
       " 54: 52,\n",
       " 55: 53,\n",
       " 56: 54,\n",
       " 57: 55,\n",
       " 58: 56,\n",
       " 59: 57,\n",
       " 60: 58,\n",
       " 61: 59,\n",
       " 62: 60,\n",
       " 63: 61,\n",
       " 64: 62,\n",
       " 65: 63,\n",
       " 66: 64,\n",
       " 67: 65,\n",
       " 69: 66,\n",
       " 68: 67,\n",
       " 70: 68,\n",
       " 71: 69,\n",
       " 72: 70,\n",
       " 73: 71,\n",
       " 74: 72,\n",
       " 75: 73,\n",
       " 76: 74,\n",
       " 77: 75,\n",
       " 78: 76,\n",
       " 79: 77,\n",
       " 80: 78,\n",
       " 81: 79,\n",
       " 82: 80,\n",
       " 83: 81,\n",
       " 84: 82,\n",
       " 85: 83,\n",
       " 86: 84,\n",
       " 87: 85,\n",
       " 88: 86,\n",
       " 89: 87,\n",
       " 90: 88,\n",
       " 91: 89,\n",
       " 92: 90,\n",
       " 93: 91,\n",
       " 94: 92,\n",
       " 95: 93,\n",
       " 96: 94,\n",
       " 97: 95,\n",
       " 98: 96,\n",
       " 99: 97,\n",
       " 100: 98,\n",
       " 101: 99,\n",
       " 102: 100,\n",
       " 103: 101,\n",
       " 104: 102,\n",
       " 106: 103,\n",
       " 107: 104,\n",
       " 109: 105,\n",
       " 110: 106,\n",
       " 111: 107,\n",
       " 105: 108,\n",
       " 112: 109,\n",
       " 113: 110,\n",
       " 108: 111,\n",
       " 114: 112,\n",
       " 120: 113,\n",
       " 119: 114,\n",
       " 121: 115,\n",
       " 129: 116,\n",
       " 126: 117,\n",
       " 128: 118,\n",
       " 123: 119,\n",
       " 135: 120}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"heroes.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    heroes_dict = {hero['id']: i for i, hero in enumerate(loads(f.read()))}\n",
    "heroes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Process data 2\n",
    "Tranform the _\"dire_lineup\"_ and _\"radiant_lineup\"_ columns, replacing the list of hero_id with an array filled with 0, except for the indeces corrisponding at the hero_id present in the original array mapped using the *heroes_dict* variable, which will have a value of 1.  \n",
    "Additionally, the type of those two columns changes from **ArrayType** to **VectorUDT**. This is required for the **VectorAssembler** to work correctly.\n",
    "\n",
    "#### Example:\n",
    "**Assuming there are a total of 10 heroes and the indeces go from 1 to 10**\n",
    "\n",
    "| dire_lineup | radiant_lineup | radiant_win | match_id |\n",
    "| - | - | - | - |\n",
    "| [2, 4, 6, 7, 8] | [1, 3, 5, 9, 10] | true | 4976549005 | \n",
    "\n",
    "Becomes\n",
    "\n",
    "| dire_lineup | radiant_lineup | radiant_win | match_id | dire_lineup_vec | radiant_lineup_vec |\n",
    "| - | - | - | - | - | - |\n",
    "| [2, 4, 6, 7, 8] | [1, 3, 5, 9, 10] | true | 4976549005 | [0, 1, 0, 1, 0, 1, 1, 1, 0, 0] | [1, 0, 1, 0, 1, 0, 0, 0, 1, 1] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+\n",
      "|         dire_lineup|      radiant_lineup|radiant_win|  match_id|     dire_lineup_vec|  radiant_lineup_vec|\n",
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+\n",
      "| [75, 88, 7, 44, 25]|[86, 41, 34, 43, ...|      false|5026549394|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "|[96, 94, 25, 103,...|[71, 67, 23, 84, 11]|      false|5026549581|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "| [2, 34, 68, 32, 76]| [53, 26, 90, 8, 75]|      false|5026549637|[0.0,1.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "|[100, 28, 26, 12,...| [2, 52, 86, 94, 30]|      false|5026549793|[0.0,0.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|\n",
      "|[129, 93, 75, 5, 35]| [73, 16, 44, 50, 2]|      false|5026549835|[0.0,0.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|\n",
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_heroes_to_lineup(df: DataFrame) -> DataFrame:\n",
    "\n",
    "    def onehot(heroes: ArrayType):\n",
    "        lineup = tuple(heroes_dict[hero] for hero in heroes)\n",
    "        return Vectors.dense([1 if hero_slot in lineup else 0 for hero_slot in range(len(heroes_dict))])\n",
    "\n",
    "    heros_to_lineup_udf = udf(onehot, VectorUDT())\n",
    "    return df.withColumn(\"dire_lineup_vec\", heros_to_lineup_udf(df.dire_lineup))\\\n",
    "             .withColumn(\"radiant_lineup_vec\", heros_to_lineup_udf(df.radiant_lineup))\n",
    "\n",
    "df = convert_heroes_to_lineup(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Process data 3\n",
    "Cast the _\"radiant_win\"_ column type from **BooleanType** to **IntegerType**.\n",
    "\n",
    "#### Example:\n",
    "**Assuming there are a total of 10 heroes and the indeces go from 1 to 10**\n",
    "\n",
    "| dire_lineup_vec | radiant_lineup_vec | dire_lineup | radiant_lineup | radiant_win | match_id |\n",
    "| - | - | - | - | - | - |\n",
    "| [0, 1, 0, 1, 0, 1, 1, 1, 0, 0] | [1, 0, 1, 0, 1, 0, 0, 0, 1, 1] | [2, 4, 6, 7, 8] | [1, 3, 5, 9, 10] | true | 4976549005 |\n",
    "\n",
    "Becomes\n",
    "\n",
    "| dire_lineup | radiant_lineup | radiant_win | match_id | dire_lineup_vec | radiant_lineup_vec | radiant_win_int |\n",
    "| - | - | - | - | - | - | - |\n",
    "| [2, 4, 6, 7, 8] | [1, 3, 5, 9, 10] | true | 4976549005 | [0, 1, 0, 1, 0, 1, 1, 1, 0, 0] | [1, 0, 1, 0, 1, 0, 0, 0, 1, 1] | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+---------------+\n",
      "|         dire_lineup|      radiant_lineup|radiant_win|  match_id|     dire_lineup_vec|  radiant_lineup_vec|radiant_win_int|\n",
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+---------------+\n",
      "| [75, 88, 7, 44, 25]|[86, 41, 34, 43, ...|      false|5026549394|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|\n",
      "|[96, 94, 25, 103,...|[71, 67, 23, 84, 11]|      false|5026549581|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|\n",
      "| [2, 34, 68, 32, 76]| [53, 26, 90, 8, 75]|      false|5026549637|[0.0,1.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|\n",
      "|[100, 28, 26, 12,...| [2, 52, 86, 94, 30]|      false|5026549793|[0.0,0.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|              0|\n",
      "|[129, 93, 75, 5, 35]| [73, 16, 44, 50, 2]|      false|5026549835|[0.0,0.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|              0|\n",
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_types(df: DataFrame) -> DataFrame:\n",
    "    return df.withColumn(\"radiant_win_int\", df.radiant_win.cast(IntegerType()))\n",
    "\n",
    "df = convert_types(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ML ðŸ¤–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ML pipeline\n",
    "The machine learning pipeline has 4 stages, but the first 2 are the same:\n",
    "```yaml\n",
    "VectorSizeHint x2: # needed for the Vector assembler, since when applyng this pipeline during a structured stream it doesn't know in advance size of the vectors\n",
    "    inputCol: dire_lineup_vec [or] radiant_lineup_vec\n",
    "    size: len(heroes_dict)\n",
    "    handleInvalid: skip\n",
    "VectorAssembler: # assembles the \"radiant_lineup_vec\" and \"dire_lineup_vec\" vectors in a single \"features\" vector\n",
    "    inputCols: ['radiant_lineup_vec', 'dire_lineup_vec']\n",
    "    outputCol: ['features']\n",
    "LogisticRegression: # uses the \"features\" vector to predict the \"radiant_win_int\" column value\n",
    "    featuresCol: ['features']\n",
    "    labelCol: ['radiant_win_int']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "size_hint_dire = VectorSizeHint(inputCol=\"dire_lineup_vec\", size=len(heroes_dict), handleInvalid=\"skip\")\n",
    "size_hint_radiant = VectorSizeHint(inputCol=\"radiant_lineup_vec\", size=len(heroes_dict), handleInvalid=\"skip\")\n",
    "vec_assembler = VectorAssembler(inputCols=['dire_lineup_vec', 'radiant_lineup_vec'], outputCol=\"features\")\n",
    "regression = LogisticRegression(featuresCol=\"features\", labelCol=\"radiant_win_int\")\n",
    "pipeline = Pipeline(stages=[size_hint_dire, size_hint_radiant, vec_assembler, regression])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ML model\n",
    "Split the original dataset in a training and test set.  \n",
    "Then use the training set to fit the model, and see the accuracy reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5724006385108628"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traint_df, test_df = df.randomSplit([0.8, 0.2])\n",
    "model = pipeline.fit(df)\n",
    "model.stages[-1].summary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML results\n",
    "Check the results by using the newly created model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|         dire_lineup|      radiant_lineup|radiant_win|  match_id|     dire_lineup_vec|  radiant_lineup_vec|radiant_win_int|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "| [6, 26, 98, 91, 93]|[74, 68, 99, 50, 34]|       true|5026562916|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|(242,[5,25,89,91,...|[-0.7954816237100...|[0.31099287208052...|       1.0|\n",
      "|  [8, 76, 74, 11, 9]|[71, 35, 46, 45, 18]|      false|5026607908|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|(242,[7,8,9,72,74...|[0.33582728285365...|[0.58317656531681...|       0.0|\n",
      "|[10, 74, 49, 63, 91]|  [94, 34, 9, 90, 2]|      false|5026643298|[0.0,0.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|              0|(242,[10,47,61,72...|[-0.3133809749344...|[0.42228969649146...|       1.0|\n",
      "|[11, 62, 70, 80, 13]|[6, 128, 71, 21, 18]|       true|5026610890|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|(242,[9,12,60,68,...|[-0.3602317315977...|[0.41090347141377...|       1.0|\n",
      "|[13, 89, 97, 101,...|[100, 56, 67, 26,...|       true|5026657238|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|(242,[12,44,87,95...|[-0.3826021363590...|[0.40549944703825...|       1.0|\n",
      "+--------------------+--------------------+-----------+----------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = model.transform(test_df)\n",
    "result_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5740614334470989"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = result_df.filter(col(\"radiant_win\").eqNullSafe(col(\"prediction\"))).count()/result_df.count()\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
