{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota match prediction based on the lineup\n",
    "The idea is to create a model able to predict the outcome of a dota match based only on the lineup of both teams.\n",
    "It is clear that the presition can never be very high: there are too many variables at play, expecially assuming the games are mostly balanced in terms of picks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Let's start by importing all the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import StructType, StructField, DataFrame\n",
    "from pyspark.sql.types import IntegerType, LongType, BooleanType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Spark Session\n",
    "Creates a Spark sessio for the app named _\"dotingestion\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cb9a9641d198:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>dotingestion</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
      "text/plain": "<pyspark.sql.session.SparkSession at 0x7f2ea233d048>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName(\"dotingestion\").getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing ðŸ”§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a schema\n",
    "This is the schema that contains all the data we need:\n",
    "```yaml\n",
    "r0: 3               # (int) radiant first pick\n",
    "r1: 14              # (int) radiant second pick\n",
    "r2: 51              # (int) radiant third pick\n",
    "r3: 113             # (int) radiant fourth pick\n",
    "r4: 135             # (int) radiant fifth pick\n",
    "d0: 41              # (int) dire first pick\n",
    "d1: 55              # (int) dire second pick\n",
    "d2: 68              # (int) dire third pick\n",
    "d3: 88              # (int) dire fourth pick\n",
    "d4: 91              # (int) dire fifth pick\n",
    "radiant_win: true   # whether the radiant team won\n",
    "match_id: 10        # sequential id of the match, to make sure each match is accounted for once\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "StructType(List(StructField(r0,IntegerType,false),StructField(r1,IntegerType,false),StructField(r2,IntegerType,false),StructField(r3,IntegerType,false),StructField(r4,IntegerType,false),StructField(d0,IntegerType,false),StructField(d1,IntegerType,false),StructField(d2,IntegerType,false),StructField(d3,IntegerType,false),StructField(d4,IntegerType,false),StructField(radiant_win,BooleanType,false),StructField(match_id,LongType,false)))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([StructField(\"r0\", IntegerType(), False),\n",
    "                    StructField(\"r1\", IntegerType(), False),\n",
    "                    StructField(\"r2\", IntegerType(), False),\n",
    "                    StructField(\"r3\", IntegerType(), False),\n",
    "                    StructField(\"r4\", IntegerType(), False),\n",
    "                    StructField(\"d0\", IntegerType(), False),\n",
    "                    StructField(\"d1\", IntegerType(), False),\n",
    "                    StructField(\"d2\", IntegerType(), False),\n",
    "                    StructField(\"d3\", IntegerType(), False),\n",
    "                    StructField(\"d4\", IntegerType(), False),\n",
    "                    StructField(\"radiant_win\", BooleanType(), False),\n",
    "                    StructField(\"match_id\", LongType(), False)])\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "Reads the matches data already collected from the _\"./data.json\"_ file.  \n",
    "Drops immedialy any null or repeated row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- r0: integer (nullable = true)\n",
      " |-- r1: integer (nullable = true)\n",
      " |-- r2: integer (nullable = true)\n",
      " |-- r3: integer (nullable = true)\n",
      " |-- r4: integer (nullable = true)\n",
      " |-- d0: integer (nullable = true)\n",
      " |-- d1: integer (nullable = true)\n",
      " |-- d2: integer (nullable = true)\n",
      " |-- d3: integer (nullable = true)\n",
      " |-- d4: integer (nullable = true)\n",
      " |-- radiant_win: boolean (nullable = true)\n",
      " |-- match_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"data.csv\"\n",
    "df = sc.read.csv(path, schema=schema, header=True).na.drop(\"all\").distinct()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "500000"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+\n",
      "| r0| r1| r2| r3| r4| d0| d1| d2| d3| d4|radiant_win|  match_id|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+\n",
      "| 42| 27| 75| 85| 39| 16|  7| 21|  1| 20|      false|5026549253|\n",
      "| 26| 12|  2| 86|123| 96| 50| 70|  6| 94|      false|5026550191|\n",
      "| 27| 48| 98|  9| 10| 52|105| 16| 96| 93|       true|5026550339|\n",
      "| 81| 86| 14|104| 70| 63|  7| 44| 23| 41|       true|5026550716|\n",
      "| 26| 44| 53| 99| 79| 29| 57| 11| 69| 60|       true|5026550933|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data 1\n",
    "The hero_id values go from 1 to 135, but not all indeces are used.  \n",
    "For this reason, first we compact them in a dictionary based on the data in the _hero.json_ file, to map each possible value to an index going from **0** to **n**, where n is the number of possible hero_id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 0,\n 2: 1,\n 3: 2,\n 4: 3,\n 5: 4,\n 6: 5,\n 7: 6,\n 8: 7,\n 9: 8,\n 11: 9,\n 10: 10,\n 12: 11,\n 13: 12,\n 14: 13,\n 15: 14,\n 16: 15,\n 17: 16,\n 18: 17,\n 19: 18,\n 20: 19,\n 21: 20,\n 22: 21,\n 23: 22,\n 25: 23,\n 31: 24,\n 26: 25,\n 27: 26,\n 28: 27,\n 29: 28,\n 30: 29,\n 32: 30,\n 33: 31,\n 34: 32,\n 35: 33,\n 36: 34,\n 37: 35,\n 38: 36,\n 39: 37,\n 40: 38,\n 41: 39,\n 42: 40,\n 43: 41,\n 44: 42,\n 45: 43,\n 46: 44,\n 47: 45,\n 48: 46,\n 49: 47,\n 50: 48,\n 51: 49,\n 52: 50,\n 53: 51,\n 54: 52,\n 55: 53,\n 56: 54,\n 57: 55,\n 58: 56,\n 59: 57,\n 60: 58,\n 61: 59,\n 62: 60,\n 63: 61,\n 64: 62,\n 65: 63,\n 66: 64,\n 67: 65,\n 69: 66,\n 68: 67,\n 70: 68,\n 71: 69,\n 72: 70,\n 73: 71,\n 74: 72,\n 75: 73,\n 76: 74,\n 77: 75,\n 78: 76,\n 79: 77,\n 80: 78,\n 81: 79,\n 82: 80,\n 83: 81,\n 84: 82,\n 85: 83,\n 86: 84,\n 87: 85,\n 88: 86,\n 89: 87,\n 90: 88,\n 91: 89,\n 92: 90,\n 93: 91,\n 94: 92,\n 95: 93,\n 96: 94,\n 97: 95,\n 98: 96,\n 99: 97,\n 100: 98,\n 101: 99,\n 102: 100,\n 103: 101,\n 104: 102,\n 106: 103,\n 107: 104,\n 109: 105,\n 110: 106,\n 111: 107,\n 105: 108,\n 112: 109,\n 113: 110,\n 108: 111,\n 114: 112,\n 120: 113,\n 119: 114,\n 121: 115,\n 129: 116,\n 126: 117,\n 128: 118,\n 123: 119,\n 135: 120}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"heroes.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    heroes_dict = {hero['id']: i for i, hero in enumerate(loads(f.read()))}\n",
    "heroes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data 2\n",
    "Tranform the _\"dire_lineup\"_ and _\"radiant_lineup\"_ columns, replacing the list of hero_id with an array filled with 0, except for the indeces corrisponding at the hero_id present in the original array mapped using the *heroes_dict* variable, which will have a value of 1.  \n",
    "Additionally, the type of those two columns changes from **ArrayType** to **VectorUDT**. This is required for the **VectorAssembler** to work correctly.\n",
    "\n",
    "#### Example:\n",
    "**Assuming there are a total of 10 heroes and the indeces go from 1 to 10**\n",
    "\n",
    "| r0 | r1 | r2 | r3 | r4 | d0 | d1 | d2 | d3 | d4 | radiant_win | match_id |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "| 2 | 4 | 6 | 7 | 8 | 1 | 3 | 5 | 9 | 10 | true | 4976549005 |\n",
    "\n",
    "Becomes\n",
    "\n",
    "| r0 | r1 | r2 | r3 | r4 | d0 | d1 | d2 | d3 | d4 | radiant_win | match_id | dire_lineup_vec | radiant_lineup_vec |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "| 2 | 4 | 6 | 7 | 8 | 1 | 3 | 5 | 9 | 10 | true | 4976549005 | [0, 1, 0, 1, 0, 1, 1, 1, 0, 0] | [1, 0, 1, 0, 1, 0, 0, 0, 1, 1] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+\n",
      "| r0| r1| r2| r3| r4| d0| d1| d2| d3| d4|radiant_win|  match_id|  radiant_lineup_vec|     dire_lineup_vec|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+\n",
      "| 42| 27| 75| 85| 39| 16|  7| 21|  1| 20|      false|5026549253|[0.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|\n",
      "| 26| 12|  2| 86|123| 96| 50| 70|  6| 94|      false|5026550191|[0.0,1.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "| 27| 48| 98|  9| 10| 52|105| 16| 96| 93|       true|5026550339|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "| 81| 86| 14|104| 70| 63|  7| 44| 23| 41|       true|5026550716|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "| 26| 44| 53| 99| 79| 29| 57| 11| 69| 60|       true|5026550933|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_heroes_to_lineup(df: DataFrame) -> DataFrame:\n",
    "\n",
    "    def onehot(l0, l1, l2, l3, l4):\n",
    "        lineup = tuple(heroes_dict[hero] for hero in (l0, l1, l2, l3, l4))\n",
    "        return Vectors.dense([1 if hero_slot in lineup else 0 for hero_slot in range(len(heroes_dict))])\n",
    "\n",
    "    heros_to_lineup_udf = udf(onehot, VectorUDT())\n",
    "    return df.withColumn(\"radiant_lineup_vec\", heros_to_lineup_udf(df.r0, df.r1, df.r2, df.r3, df.r4))\\\n",
    "             .withColumn(\"dire_lineup_vec\", heros_to_lineup_udf(df.d0, df.d1, df.d2, df.d3, df.d4))\n",
    "\n",
    "df = convert_heroes_to_lineup(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data 3\n",
    "Cast the _\"radiant_win\"_ column type from **BooleanType** to **IntegerType**.\n",
    "\n",
    "#### Example:\n",
    "**Assuming there are a total of 10 heroes and the indeces go from 1 to 10**\n",
    "\n",
    "| r0 | r1 | r2 | r3 | r4 | d0 | d1 | d2 | d3 | d4 | radiant_win | match_id | radiant_lineup_vec | dire_lineup_vec |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "| 2 | 4 | 6 | 7 | 8 | 1 | 3 | 5 | 9 | 10 | true | 4976549005 | [0, 1, 0, 1, 0, 1, 1, 1, 0, 0] | [1, 0, 1, 0, 1, 0, 0, 0, 1, 1] |\n",
    "\n",
    "Becomes\n",
    "\n",
    "| r0 | r1 | r2 | r3 | r4 | d0 | d1 | d2 | d3 | d4 | radiant_win | match_id | radiant_lineup_vec | dire_lineup_vec | radiant_win_int |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - | - | - | - |\n",
    "| 2 | 4 | 6 | 7 | 8 | 1 | 3 | 5 | 9 | 10 | true | 4976549005 | [0, 1, 0, 1, 0, 1, 1, 1, 0, 0] | [1, 0, 1, 0, 1, 0, 0, 0, 1, 1] | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+---------------+\n",
      "| r0| r1| r2| r3| r4| d0| d1| d2| d3| d4|radiant_win|  match_id|  radiant_lineup_vec|     dire_lineup_vec|radiant_win_int|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+---------------+\n",
      "| 42| 27| 75| 85| 39| 16|  7| 21|  1| 20|      false|5026549253|[0.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|              0|\n",
      "| 26| 12|  2| 86|123| 96| 50| 70|  6| 94|      false|5026550191|[0.0,1.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|\n",
      "| 27| 48| 98|  9| 10| 52|105| 16| 96| 93|       true|5026550339|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|\n",
      "| 81| 86| 14|104| 70| 63|  7| 44| 23| 41|       true|5026550716|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|\n",
      "| 26| 44| 53| 99| 79| 29| 57| 11| 69| 60|       true|5026550933|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_types(df: DataFrame) -> DataFrame:\n",
    "    return df.withColumn(\"radiant_win_int\", df.radiant_win.cast(IntegerType()))\n",
    "\n",
    "df = convert_types(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler, VectorSizeHint\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML pipeline\n",
    "The machine learning pipeline has 4 stages, but the first 2 are the same:\n",
    "```yaml\n",
    "VectorSizeHint x2: # needed for the Vector assembler, since when applyng this pipeline during a structured stream it doesn't know in advance size of the vectors\n",
    "    inputCol: dire_lineup_vec [or] radiant_lineup_vec\n",
    "    size: len(heroes_dict)\n",
    "    handleInvalid: skip\n",
    "VectorAssembler: # assembles the \"radiant_lineup_vec\" and \"dire_lineup_vec\" vectors in a single \"features\" vector\n",
    "    inputCols: ['radiant_lineup_vec', 'dire_lineup_vec']\n",
    "    outputCol: ['features']\n",
    "LogisticRegression: # uses the \"features\" vector to predict the \"radiant_win_int\" column value\n",
    "    featuresCol: ['features']\n",
    "    labelCol: ['radiant_win_int']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_hint_dire = VectorSizeHint(inputCol=\"dire_lineup_vec\", size=len(heroes_dict), handleInvalid=\"skip\")\n",
    "size_hint_radiant = VectorSizeHint(inputCol=\"radiant_lineup_vec\", size=len(heroes_dict), handleInvalid=\"skip\")\n",
    "vec_assembler = VectorAssembler(inputCols=['dire_lineup_vec', 'radiant_lineup_vec'], outputCol=\"features\")\n",
    "regression = LogisticRegression(featuresCol=\"features\", labelCol=\"radiant_win_int\")\n",
    "pipeline = Pipeline(stages=[size_hint_dire, size_hint_radiant, vec_assembler, regression])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param grid and CrossValidator\n",
    "The param grid and the CrossValidator allow to run the same fit operation multiple time, altering the hyperparamentes to try and find the set that optimizes the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(regression.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .addGrid(regression.maxIter,[1000])\\\n",
    "    .addGrid(regression.regParam,[0.01, 0.5, 2.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=BinaryClassificationEvaluator(labelCol=\"radiant_win_int\")\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML model\n",
    "Split the original dataset in a training and test set.  \n",
    "Then use the training set to fit the model, and see the accuracy reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "traint_df, test_df = df.randomSplit([0.8, 0.2])\n",
    "model = cv.fit(traint_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML results\n",
    "Check the results by using the newly created model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "| r0| r1| r2| r3| r4| d0| d1| d2| d3| d4|radiant_win|  match_id|  radiant_lineup_vec|     dire_lineup_vec|radiant_win_int|            features|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|  1| 20| 13|108| 50| 94| 74| 88| 87| 76|      false|5026795783|[1.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|(242,[72,74,85,86...|[-0.1187791040452...|[0.47034008713804...|       1.0|\n",
      "|  1| 84| 96| 13| 45| 99| 70| 62| 30| 36|      false|5027387970|[1.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|(242,[29,34,60,68...|[0.05718586068549...|[0.51429257039301...|       0.0|\n",
      "|  1| 95| 64| 23|104|  8|110| 75| 63|119|       true|5026648055|[1.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              1|(242,[7,61,73,106...|[-0.1333776232239...|[0.46670493835801...|       1.0|\n",
      "|  1|101|  4|  2| 53| 74|114| 27|105| 96|      false|5026619908|[1.0,1.0,0.0,1.0,...|[0.0,0.0,0.0,0.0,...|              0|(242,[26,72,94,10...|[-0.1674276056066...|[0.45824060301560...|       1.0|\n",
      "|  1|105|  8|135| 59| 34| 93| 26| 36| 74|      false|5026634106|[1.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|              0|(242,[25,32,34,72...|[-0.1068897678811...|[0.47330297192609...|       1.0|\n",
      "+---+---+---+---+---+---+---+---+---+---+-----------+----------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = model.transform(test_df)\n",
    "result_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set after CV  is 0.5923819498967543\n",
      "The area under ROC for test set after CV  is 0.590186560695288\n"
     ]
    }
   ],
   "source": [
    "predict_train=model.transform(traint_df)\n",
    "predict_test=model.transform(test_df)\n",
    "print(\"The area under ROC for train set after CV  is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set after CV  is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cv_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "name": "python373jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}